<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[3GID.GITHUB.IO]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>3GID.GITHUB.IO</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 19 Aug 2024 05:47:16 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 19 Aug 2024 05:47:16 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[모각코 최종 회고]]></title><description><![CDATA[ 
 <br>학번 : 202102563<br>이름 : 김동현<br>목표 : SAR 데이터 셋 segmentation 인공지능 모델 구현<br>회고 - 인공지능 모델 중 segmentation 이라는 이미지 분류 모델에 대하여 보다 자세히 공부하며 어떤 식으로 구성되어 만들어 지는 것인가 대하여 알아보는 좋은 기회였다.  팀원들과  같은 목표에 대하여 공부하며 토론해보니 내가 알고 있던 정보와 다른 내용을 알 수 있어서 효과적이었다.]]></description><link>모각코-최종-회고.html</link><guid isPermaLink="false">모각코 최종 회고.md</guid><pubDate>Mon, 19 Aug 2024 05:42:27 GMT</pubDate></item><item><title><![CDATA[[하계 모각코] 1차 학습 및  결과]]></title><description><![CDATA[ 
 <br>주차 목표 <br>
<br>각자 블로그 만들기 
<br>segmentation에 대해 간단하게 알아보기 
<br>어떻게 진행할 지 회의
<br>활동 결과 <br>
<br>깃허브 블로그 만들기
<br>segmentation 관련 자료 공부 진행방식 같은 목표와 주제를 가지고 각자 공부한 것에 대해 토론하고 피드백해주는 방식으로 진행하기로 함. 
<br>학습 내용<br>이미지 처리(Image Processing) 에는 4가지 종류가 있다.<br>
Image Classification  ,Image Localization , Object Detection , Image Segmentation<br>
Segmentation의 목적은 이미지의 각각의 픽셀들을 특정 클래스로 분류하는 방식이다.<br>
이 방식은 의학 사진, 자율주행 , 위성 이미지 분석등등 다양하게 사용된다.<br>학습을 통해 segmentation 모델을 만들 수 있는데, 이때 학습을 위한 데이터 셋이 필요하다. 데이터 셋은 이미지와 이미지에 대한 정보가 text로 나와있는 annotation으로 구성된다.<br>
이미지를 annotation을 이용하여 masking 이라는 작업을 하면<br>
결과물이 나오는데 이를 이용하여 segmetation 모델의 학습을 할 수 있다.<br><a rel="noopener" class="external-link" href="https://velog.io/@lighthouse97/%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%84%B8%EA%B7%B8%EB%A9%98%ED%85%8C%EC%9D%B4%EC%85%98Image-Segmentation" target="_blank">https://velog.io/@lighthouse97/%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%84%B8%EA%B7%B8%EB%A9%98%ED%85%8C%EC%9D%B4%EC%85%98Image-Segmentation</a><br><a rel="noopener" class="external-link" href="https://velog.io/@aerojohn1223/Object-Detection%EA%B3%BC-Segmentation%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A3%BC%EC%9A%94-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B-%EB%B0%8F-OpenCV-%EC%86%8C%EA%B0%9C-%EC%A0%95%EB%A6%AC" target="_blank">https://velog.io/@aerojohn1223/Object-Detection%EA%B3%BC-Segmentation%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%A3%BC%EC%9A%94-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B-%EB%B0%8F-OpenCV-%EC%86%8C%EA%B0%9C-%EC%A0%95%EB%A6%AC</a><br><a rel="noopener" class="external-link" href="https://pyimagesearch.com/2020/09/28/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/" target="_blank">https://pyimagesearch.com/2020/09/28/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/</a>]]></description><link>모각코\[하계-모각코]-1차-학습-및-결과.html</link><guid isPermaLink="false">모각코/[하계 모각코] 1차 학습 및  결과.md</guid><pubDate>Sun, 18 Aug 2024 13:05:12 GMT</pubDate></item><item><title><![CDATA[[하계 모각코] 2차 학습 및 결과]]></title><description><![CDATA[ 
 <br>주차 목표 <br>
<br>segemenation에서 coco데이터 객체가 쓰이는 이유 알아보기
<br>coco 데이터가 어떻게 구성되어 있는지 알아보기 
<br>활동 결과 <br>
<br>computer vision에서  coco데이터의 쓰임 확인
<br>coco 데이터 관련 공부
<br>학습 내용<br>
COCO 데이터 셋은 객체 탐지 (object detection), 세그먼테이션 (segmentation), 키포인트 탐지 (keypoint detection) 등의 컴퓨터 비전(computer vision)분야의 task를 목적으로 만들어진 데이터 셋이다. COCO 데이터 셋은 이미지 파일과 annotation 파일로 구성 된다.<br>
annotation 파일에는 json으로 구성된 파일이  존재하는데 이는 key : value로 구성된 dictionary 형식이며 이미지 파일에 대한 정보를 담고있다. 이는 해당 이미지의 라이센스 , 파일 이름 , url , 높이 ,넓이 또는 해당 사물이 이미지 내 어떤 위치에 있는지인 구체적인 바운딩 박스에 대한 정보를 포함한다.<br><a rel="noopener" class="external-link" href="https://ndb796.tistory.com/667" target="_blank">https://ndb796.tistory.com/667</a>]]></description><link>모각코\[하계-모각코]-2차-학습-및-결과.html</link><guid isPermaLink="false">모각코/[하계 모각코] 2차 학습 및 결과.md</guid><pubDate>Sun, 18 Aug 2024 13:05:17 GMT</pubDate></item><item><title><![CDATA[[하계 모각코] 6차 학습 및 결과]]></title><description><![CDATA[ 
 <br>주차 목표 <br>
<br>segmentation 모델 구조인 Unet에 대해 알아보기
<br>모델 결과에 대해 확인하기
<br>그동안 모각코 진행한 것에 대하여 질문하고 정리하는 시간을 가지기
<br>활동 결과 <br>
<br>모델 학습 후 precision과 recall 확인
<br>그동안 학습한 내용들 정리 후 각자 질문 및 마무리 시간
<br>학습 내용<br>
U -Net이란 cnn의 원리를 이용한 복잡한 인공지능 모델이다.<br>
이는 적은 수의 학습데이터로도 높은 정확성의 이미지 세그멘테이션 성능을 보여준다.<br>
U-Net은 인코더-디코더 기반 모델에 속하는데 인코딩 단계에서는 특징을 포착할 수 있도록 차원을 축소하고 디코딩 단계에서는 차원을 늘려 고차원의 이미지를 복원한다.<br>
이과정에서 이미지 객체에 대한 자세한 위치 정보를 잃게 되고 정보손실이 일어나게 된다.<br>
U-Net의 기본 아이디어는 저차원 뿐만 아니라 고차원 정보도 이용하여 이미지의 특징을 추출함과 동시에 정확한 위치 파악도 가능하게 하자는 것이다.<br>
이를 통하여 기존 인코더 -디코더 모델에서 발생하는 정보손실에 대하여 보완이 된다.<br>모델생성 후 학습을 시키며 결과가 도출되는데 accuracy가 아닌 precison과 recall이라는 정보가 도출된다. precision(정밀도)은 모델이 True라고 분류한 것 중 실제 True 인 것의 비율이다. Positive는 모델이 True라고 예측한 경우이다.<br>
True Positive 는 모델이 True라고 판단한 것이 실제 True인 경우이고<br>
False Positve는 모델이 True라고 판단한것 중 실제로 False 인경우이다. precison은 TP/TP+FP라는 식으로 표현되며 이는 Positve 정답률,PPV 라고도 불린다.<br>Reacll(재현율)은 실제 True인 것 중 모델이 True라고 예측한 것의 비율이다.<br>
Negetive는 모델이 False라고 예측한 경우이다.<br>
False Negetaive는 정답이 True인 경우 모델이 False라고 예측한 경우이다.<br>
Recall은 (True Positive + False Negetive) % True Positve 라는 식 즉<br>
TP / TP+FN 로 나타낼 수 있다.<br>
이와 같은 결과를 통해 모델의 성능을 확인하고 개선시킬 수 있다.<br><a rel="noopener" class="external-link" href="https://sumniya.tistory.com/26" target="_blank">https://sumniya.tistory.com/26</a><br>
<a rel="noopener" class="external-link" href="https://www.deepcampus.kr/204" target="_blank">https://www.deepcampus.kr/204</a>]]></description><link>모각코\[하계-모각코]-6차-학습-및-결과.html</link><guid isPermaLink="false">모각코/[하계 모각코] 6차 학습 및 결과.md</guid><pubDate>Sun, 18 Aug 2024 14:14:49 GMT</pubDate></item><item><title><![CDATA[[하계 모각코] 4차 학습 및 결과]]></title><description><![CDATA[ 
 <br>주차 목표 <br>
<br>segmentation에서 mask를 만드는 함수를 통해 mask 데이터를 만드는 법을 알아보기
<br>tensorflow를 이용하여 인공지능 모델 학습에 쓰일 데이터셋을 만드는 법 알아보기
<br>활동 결과 <br>
<br>segmentation에서 모든 Image에 대해 annotation 파일을 이용해서 mask데이터를 만드는 방법
<br>image와 mask 파일을 이용하여 데이터 셋을 만드는 방법
<br>학습 내용<br>
인공지능 모델 학습에 필요한 데이터 셋을 만들기 위해서는 저번에 공부한 image와<br>
annotation 파일을 통해서 mask를 만들고 이를 정리 해야 한다.<br>
이에 대하여 필요한 함수들이 몇 가지 있는데 mask 생성 함수를 통하여 image와 annotation에 정보를 통해 mask를 만들고 이를 모든 이미지에 대하여 생성해야 하므로 annotation에 있는 image id를 불러와 모든 이미지에 대한 mask 생성 함수를 실행해주는 함수가 필요하다. image와 mask를 짝 지어야 하므로 이를 pair 해주는 함수, 시각화 하여 보기 위한 plt 라이브러리를 사용한 함수 , 데이터 셋 경로와 ima*ge size, batch size 등을 설정해주는 함수 등이 필요하다.<br>
tensorflow라는 python  라이브러리를 통해 image경로, mask 경로, pair 경로등을 사용하여  학습 시에 필요한 데이터 셋을 만들 수 있다.<br>
이 과정을 통하여 데이터 셋 구성이 완료된다.<br><a rel="noopener" class="external-link" href="https://soundprovider.tistory.com/entry/Tensorflow-tfds%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-custom-dataset-%EC%83%9D%EC%84%B1" target="_blank">https://soundprovider.tistory.com/entry/Tensorflow-tfds%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-custom-dataset-%EC%83%9D%EC%84%B1</a>]]></description><link>모각코\[하계-모각코]-4차-학습-및-결과.html</link><guid isPermaLink="false">모각코/[하계 모각코] 4차 학습 및 결과.md</guid><pubDate>Fri, 16 Aug 2024 12:04:32 GMT</pubDate></item><item><title><![CDATA[[하계 모각코] 5차 학습 및 결과]]></title><description><![CDATA[ 
 <br>주차 목표 <br>
<br>segmentation 모델을 만들기 위해 CNN 아키텍쳐에 대해 알아보기
<br>CNN 아키텍쳐의 기본 개념들에 대해 이해한 후, Unet 모델에 대해서 코드 구성
<br>활동 결과 <br>
<br>Unet 모델 만들기에 대하여 학습
<br>CNN 아키텍쳐 구조에 관하여 학습
<br>학습 내용<br>
CNN 모델은  컴퓨터 비전 분야에서 많이 사용되는  인공지능 신경망 모델 중 하나이다. CNN이란&nbsp;동물의 시각 피질의 구조에서 영감을 받아 만들어진 딥러닝 신경망 모델로 특징을 추출하는 Convloution 층과 정보를 압축하는 Pooling 층의 반복 그리고 후반에 다층 퍼셉트론 층으로 이루어져 있다.<br>컨볼루션 층 이란 특징을 추출하는 층으로 이미지에 행렬 값에 대하여 '필터' 값을 곱해준 뒤 모두 합쳐서 얻은 값을 다음 층에 넘겨준다.<br>
풀링층은 일정 크기의 블록을 통합하여 하나의 대표값으로 대체하는 연산으로&nbsp;컨볼루션&nbsp;층에서 출력된 특징 지도를 압축하여 특정 데이터를 강조하는 역할을 한다.<br>
완전 연결층에서는 추출된 특징을&nbsp;하여 분류 작업을 수행할 수 있는 형태로 변환합니다. 컨볼루션층과 풀링층의 반복된 연산으로 축소된 이미지 배열은 특징들 만을 포함한 하나의 1차원 배열 데이터로 변환된다.<br>
이후 학습을 진행하며 도출되는 accuracy나 precision 같은 지표들을 통하여 변화 과정을 알 수 있다.<br><a rel="noopener" class="external-link" href="https://idplab-konkuk.tistory.com/13" target="_blank">https://idplab-konkuk.tistory.com/13</a><br>
<a rel="noopener" class="external-link" href="https://resultofeffort.tistory.com/89" target="_blank">https://resultofeffort.tistory.com/89</a>]]></description><link>모각코\[하계-모각코]-5차-학습-및-결과.html</link><guid isPermaLink="false">모각코/[하계 모각코] 5차 학습 및 결과.md</guid><pubDate>Fri, 16 Aug 2024 12:49:35 GMT</pubDate></item><item><title><![CDATA[[하계 모각코] 3차 학습 및 결과]]></title><description><![CDATA[ 
 <br>주차 목표 <br>
<br>segemenation에서 mask를 왜 만들어야 하는지 알아보기
<br>우리가 가진 데이터 셋에서 mask를 만드는 방법에 대해 알아보기 
<br>활동 결과 <br>
<br>segmentation에서 mask의 역할에 대해서
<br>우리가 가진 데이터 셋에서 mask를 만드는 방법
<br>학습 내용<br>
마스크 함수의 역할은 주어진 데이터 또는 모델의 입력에 대한 마스크를 생성하거나 조작하는 것이다.&nbsp;주로 딥러닝 모델의 어텐션 메커니즘, 시퀀스 처리, 이미지 처리 등 다양한 작업에서 사용된다. 특정 부분에 대한 주의를 집중하거나, 정보를 가리거나 보호하여 모델이 올바른 패턴을 학습하고 불필요한 정보를 무시하도록 도와준다.<br>
우리가 사용할 모델은 바다 위에 떠 있는 해양 선박을 인식하는 모델이므로 ,<br>
이를 masking 하면 image에 있는 선박의 좌표를 annotation에 있는 좌표 정보를 통해서 만들 수 있다. 이를 통해 모델 학습에 필요한 mask를 얻을 수 있다.<br><a rel="noopener" class="external-link" href="https://applepy.tistory.com/m/168" target="_blank">https://applepy.tistory.com/m/168</a>]]></description><link>모각코\[하계-모각코]-3차-학습-및-결과.html</link><guid isPermaLink="false">모각코/[하계 모각코] 3차 학습 및 결과.md</guid><pubDate>Thu, 08 Aug 2024 13:26:34 GMT</pubDate></item><item><title><![CDATA[Vault]]></title><description><![CDATA[ 
 ]]></description><link>vault.html</link><guid isPermaLink="false">Vault.md</guid><pubDate>Thu, 01 Aug 2024 08:47:07 GMT</pubDate></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br><br>=======<br>
sticker: emoji//1f643<br><br>Main Page<br>






20fb5df35220af3006e1413aabadf07f8508ca11






]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Thu, 01 Aug 2024 08:40:20 GMT</pubDate></item><item><title><![CDATA[Obsidian template for using github.io]]></title><description><![CDATA[ 
 <br>]]></description><link>readme.html</link><guid isPermaLink="false">README.md</guid><pubDate>Wed, 26 Jun 2024 12:40:01 GMT</pubDate></item></channel></rss>